{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Timothy/repository/cs233_gtda_hw4/hw4_env/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available()\n\u001b[1;32m      2\u001b[0m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mdevice_count()\n\u001b[0;32m----> 3\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_device_name\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/repository/cs233_gtda_hw4/hw4_env/lib/python3.9/site-packages/torch/cuda/__init__.py:328\u001b[0m, in \u001b[0;36mget_device_name\u001b[0;34m(device)\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_device_name\u001b[39m(device: Optional[_device_t] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m    317\u001b[0m     \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Gets the name of a device.\u001b[39;00m\n\u001b[1;32m    318\u001b[0m \n\u001b[1;32m    319\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[38;5;124;03m        str: the name of the device\u001b[39;00m\n\u001b[1;32m    327\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 328\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_device_properties\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mname\n",
      "File \u001b[0;32m~/repository/cs233_gtda_hw4/hw4_env/lib/python3.9/site-packages/torch/cuda/__init__.py:358\u001b[0m, in \u001b[0;36mget_device_properties\u001b[0;34m(device)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_device_properties\u001b[39m(device: _device_t) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m _CudaDeviceProperties:\n\u001b[1;32m    349\u001b[0m     \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Gets the properties of a device.\u001b[39;00m\n\u001b[1;32m    350\u001b[0m \n\u001b[1;32m    351\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    356\u001b[0m \u001b[38;5;124;03m        _CudaDeviceProperties: the properties of the device\u001b[39;00m\n\u001b[1;32m    357\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 358\u001b[0m     \u001b[43m_lazy_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# will define _get_device_properties\u001b[39;00m\n\u001b[1;32m    359\u001b[0m     device \u001b[38;5;241m=\u001b[39m _get_device_index(device, optional\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    360\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m device \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m device \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m device_count():\n",
      "File \u001b[0;32m~/repository/cs233_gtda_hw4/hw4_env/lib/python3.9/site-packages/torch/cuda/__init__.py:210\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    207\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    208\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultiprocessing, you must use the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspawn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m start method\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    209\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(torch\u001b[38;5;241m.\u001b[39m_C, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_cuda_getDeviceCount\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m--> 210\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTorch not compiled with CUDA enabled\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    211\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _cudart \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    212\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[1;32m    213\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "torch.cuda.is_available()\n",
    "torch.cuda.device_count()\n",
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "import os.path as osp\n",
    "import tqdm\n",
    "import matplotlib.pylab as plt\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from collections import defaultdict\n",
    "\n",
    "## Imports based on our ready-to-use code (after you pip-install the cs233_gtda_hw4 package)\n",
    "from cs233_gtda_hw4.in_out.utils import make_data_loaders\n",
    "from cs233_gtda_hw4.in_out.utils import save_state_dicts, load_state_dicts\n",
    "from cs233_gtda_hw4.in_out import pointcloud_dataset\n",
    "from cs233_gtda_hw4.in_out.plotting import plot_3d_point_cloud\n",
    "\n",
    "\n",
    "## Imports you might use if you follow are scaffold code (it is OK to use your own stucture of the models)\n",
    "from cs233_gtda_hw4.models import PointcloudAutoencoder\n",
    "from cs233_gtda_hw4.models import PartAwarePointcloudAutoencoder\n",
    "from cs233_gtda_hw4.models.point_net import PointNet\n",
    "from cs233_gtda_hw4.models.mlp import MLP\n",
    "from cs233_gtda_hw4.models.part_classifier import part_classifier\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "## Fixed Settings (we do not expect you to change these)\n",
    "## \n",
    "\n",
    "n_points = 1024  # number of points of each point-cloud\n",
    "n_parts = 4      # max number of parts of each shape\n",
    "n_train_epochs = 400\n",
    "\n",
    "# Students: feel free to change below -ONLY- for the bonus Question:\n",
    "# I.e., use THESE hyper-parameters when you train for the non-bonus questions.\n",
    "\n",
    "part_lambda = 0.005  # for the part-aware AE you will be using (summing) two losses:\n",
    "                     # chamfer + cross-entropy\n",
    "                     # do it like this: chamfer + (part_lambda * cross-entropy), \n",
    "                     # i.e. we are scaling down the cross-entropy term\n",
    "init_lr = 0.009  # initial learning-rate, tested by us with ADAM optimizer (see below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Students: feel free to change below:\n",
    "\n",
    "# batch-size of data loaders\n",
    "batch_size = 128 # if you can keep this too as is keep it, \n",
    "                 # but if it is too big for your GPU, feel free to change it.\n",
    "\n",
    "# which device to use: cpu or cuda?\n",
    "#device = 'cpu'     # Note: only the \"alternative\" (slower) chamfer_loss in losses/nn_distance can run in cpu.\n",
    "device = 'cuda'\n",
    "\n",
    "top_in_dir = '../data/'\n",
    "top_out_dir = '../data/out/'\n",
    "if not osp.exists(top_out_dir):\n",
    "    os.makedirs(top_out_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREPARE DATA:\n",
    "\n",
    "loaders = make_data_loaders(top_in_dir, batch_size)\n",
    "\n",
    "for split, loader in loaders.items():\n",
    "    print('N-examples', split, len(loader.dataset))\n",
    "    \n",
    "# BUILD MODELS:\n",
    "### TODO: Student on your own:\n",
    "NUM_POINTS = 1024\n",
    "NUM_CHANNELS = 3\n",
    "LATENT_DIM = 128\n",
    "# batch_size, num_channels, num_points\n",
    "\n",
    "encoder = PointNet(NUM_CHANNELS)\n",
    "decoder = MLP(LATENT_DIM, NUM_POINTS)\n",
    "part_classifier = part_classifier(LATENT_DIM+NUM_CHANNELS, n_parts, 0.005)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "part_aware_model = False # or True\n",
    "\n",
    "if part_aware_model:\n",
    "    xentropy = nn.CrossEntropyLoss()\n",
    "    model = PartAwarePointcloudAutoencoder(encoder, decoder, part_classifier, part_lambda).to(device) # Students Work here\n",
    "    model_tag = 'part_pc_ae'\n",
    "else:\n",
    "    model = PointcloudAutoencoder(encoder, decoder).to(device)  # Students Work here\n",
    "    model_tag = 'pc_ae'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=init_lr)  # Students uncomment once you have defined your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train for multiple epochs your model.\n",
    "# Students: the below for-loops are optional, feel free to structure your training \n",
    "# differently.\n",
    "\n",
    "min_val_loss = np.Inf\n",
    "out_file = osp.join(top_out_dir, model_tag + 'best_model.pth')\n",
    "start_epoch = 1\n",
    "train_loss = []\n",
    "val_loss = []\n",
    "test_loss = []\n",
    "\n",
    "for epoch in tqdm.tqdm(range(start_epoch, start_epoch + n_train_epochs)):\n",
    "    for phase in ['train', 'val', 'test']:        \n",
    "        ### Students Work Here.\n",
    "        recon_loss = model.train_for_one_epoch(loaders[phase], optimizer, device)\n",
    "        print(phase, \" loss: \", recon_loss)\n",
    "        if phase == 'train':\n",
    "            train_loss.append(recon_loss.item())\n",
    "        elif phase == 'val':\n",
    "            val_loss.append(recon_loss.item())\n",
    "        elif phase == 'test':\n",
    "            test_loss.append(recon_loss.item())\n",
    "            \n",
    "        if phase == 'val' and recon_loss < min_val_loss: # Save model if validation loss improved.\n",
    "            min_val_loss = recon_loss\n",
    "            save_state_dicts(out_file, epoch=epoch, model=model) # If you save the model like this, you can use the code below to load it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(ncols=3, figsize=(20, 4))\n",
    "\n",
    "axes[0].plot(range(n_train_epochs), train_loss, label='Train loss')\n",
    "axes[0].set_title('Training Loss')\n",
    "axes[1].plot(range(n_train_epochs), val_loss, label='Val loss')\n",
    "axes[1].set_title('Validation Loss')\n",
    "axes[2].plot(range(n_train_epochs), test_loss, label='Test loss')\n",
    "axes[2].set_title('Test Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model with best per-validation loss (uncomment when ready)\n",
    "best_epoch = load_state_dicts(out_file, model=model)\n",
    "print('per-validation optimal epoch', best_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconstruct from best model\n",
    "recons, losses = model.reconstruct(loaders['test'], device=device)\n",
    "recons = torch.cat(recons, dim=0)\n",
    "losses = torch.cat(losses, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recon_losses = losses.cpu().numpy()\n",
    "mean_loss = np.mean(recon_losses)\n",
    "print('Reconstruction loss: ', mean_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Students TODO: MAKE your plots and analysis\n",
    "\n",
    "# 5 examples to visualize per questions (e, f)\n",
    "examples_to_visualize = ['8a67fd47001e52414c350d7ea5fe2a3a',\n",
    "                         '1e0580f443a9e6d2593ebeeedbff73b',\n",
    "                         'd3562f992aa405b214b1fd95dbca05',\n",
    "                         '4e8d8792a3a6390b36b0f2a1430e993a',\n",
    "                         '58479a7b7c157865e68f66efebc71317']\n",
    "# You can (also) use the function for the reconstructions or the part-predictions \n",
    "# (for the latter check the kwargs parameter 'c' of matplotlib.\n",
    "# plot_3d_point_cloud, eg. try plot_3d_point_cloud(loaders['test'].dataset.pointclouds[0])\n",
    "\n",
    "for example in examples_to_visualize:\n",
    "    print(\"Example: \", example)\n",
    "    index = np.where(loaders['test'].dataset.model_names == example)\n",
    "    index = np.int(index[0])\n",
    "    \n",
    "    \n",
    "    # Plot side by side\n",
    "    #f, axarr = plt.subplots(1,2)\n",
    "    \n",
    "    orig = plot_3d_point_cloud(loaders['test'].dataset.pointclouds[index], title = 'original')\n",
    "    recon = plot_3d_point_cloud(recons[index].cpu(), title = 'reconstructed')\n",
    "    \n",
    "    #axarr[1].imshow(recon)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#model.eval()   # Do not forget this.! We are not training any more (OK, since we do not \n",
    "               # have batch-norm, drop-out etc. this is not so important, however it is good standard \n",
    "               # practice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best and worst\n",
    "min_example = recon_losses.argmin()\n",
    "max_example = recon_losses.argmax()\n",
    "\n",
    "print(\"Best Example: \", example)\n",
    "print(\"Chamfer distance: \", recon_losses.min())\n",
    "orig = plot_3d_point_cloud(loaders['test'].dataset.pointclouds[min_example], title = 'original')\n",
    "recon = plot_3d_point_cloud(recons[min_example].cpu(), title = 'reconstructed')\n",
    "\n",
    "print(\"Worst Example: \", example)\n",
    "print(\"Chamfer distance: \", recon_losses.max())\n",
    "orig = plot_3d_point_cloud(loaders['test'].dataset.pointclouds[max_example], title = 'original')\n",
    "recon = plot_3d_point_cloud(recons[max_example].cpu(), title = 'reconstructed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()   # Do not forget this.! We are not training any more (OK, since we do not \n",
    "               # have batch-norm, drop-out etc. this is not so important, however it is good standard \n",
    "               # practice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Last, save the latent codes of the test data and go to the \n",
    "# measuring_part_awareness and tsne_plot_with_latent_codes code.\n",
    "\n",
    "# Students TODO: Extract the latent codes and save them, so you can analyze them later.\n",
    "latent_codes, test_names = model.extract_latent_code(loaders['test'], device=device)   \n",
    "\n",
    "latent_codes = latent_codes.cpu()\n",
    "\n",
    "np.savez(osp.join(top_out_dir, model_tag +'_latent_codes'), \n",
    "         latent_codes=latent_codes, \n",
    "         test_names=test_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Part-aware model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "part_aware_model = True # or True\n",
    "\n",
    "if part_aware_model:\n",
    "    xentropy = nn.CrossEntropyLoss()\n",
    "    model = PartAwarePointcloudAutoencoder(encoder, decoder, part_classifier, part_lambda).to(device) # Students Work here\n",
    "    model_tag = 'part_pc_ae'\n",
    "else:\n",
    "    model = PointcloudAutoencoder(encoder, decoder).to(device)  # Students Work here\n",
    "    model_tag = 'pc_ae'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=init_lr)  # Students uncomment once you have defined your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train for multiple epochs your model.\n",
    "# Students: the below for-loops are optional, feel free to structure your training \n",
    "# differently.\n",
    "\n",
    "min_val_loss = np.Inf\n",
    "out_file = osp.join(top_out_dir, model_tag + 'best_model.pth')\n",
    "start_epoch = 1\n",
    "\n",
    "train_xe_loss = []\n",
    "val_xe_loss = []\n",
    "test_xe_loss = []\n",
    "\n",
    "\n",
    "train_chamfer_loss = []\n",
    "val_chamfer_loss = []\n",
    "test_chamfer_loss = []\n",
    "\n",
    "train_joint_loss = []\n",
    "val_joint_loss = []\n",
    "test_joint_loss = []\n",
    "\n",
    "\n",
    "for epoch in tqdm.tqdm(range(start_epoch, start_epoch + n_train_epochs)):\n",
    "    for phase in ['train', 'val', 'test']:        \n",
    "        ### Students Work Here.\n",
    "        joint_loss, chamfer_loss, xe_loss = model.train_for_one_epoch(loaders[phase], optimizer, device)\n",
    "        print(phase, \"joint loss: \", joint_loss, \" chamfer loss: \", chamfer_loss, \"xe loss: \", xe_loss)\n",
    "        if phase == 'train':\n",
    "            train_chamfer_loss.append(chamfer_loss.item())\n",
    "            train_joint_loss.append(joint_loss.item())\n",
    "            train_xe_loss.append(xe_loss.item())\n",
    "        elif phase == 'val':\n",
    "            val_chamfer_loss.append(chamfer_loss.item())\n",
    "            val_joint_loss.append(joint_loss.item())\n",
    "            val_xe_loss.append(xe_loss.item())\n",
    "        elif phase == 'test':\n",
    "            test_chamfer_loss.append(chamfer_loss.item())\n",
    "            test_joint_loss.append(joint_loss.item())\n",
    "            test_xe_loss.append(xe_loss.item())\n",
    "            \n",
    "        if phase == 'val' and joint_loss < min_val_loss: # Save model if validation loss improved.\n",
    "            min_val_loss = joint_loss\n",
    "            save_state_dicts(out_file, epoch=epoch, model=model) # If you save the model like this, you can use the code below to load it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(ncols=3, figsize=(20, 4))\n",
    "\n",
    "fig.suptitle(\"Chamfer loss\")\n",
    "axes[0].plot(range(n_train_epochs), train_chamfer_loss, label='Train loss')\n",
    "axes[0].set_title('Training Loss')\n",
    "axes[1].plot(range(n_train_epochs), val_chamfer_loss, label='Val loss')\n",
    "axes[1].set_title('Validation Loss')\n",
    "axes[2].plot(range(n_train_epochs), test_chamfer_loss, label='Test loss')\n",
    "axes[2].set_title('Testing Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(ncols=3, figsize=(20, 4))\n",
    "\n",
    "fig.suptitle(\"Cross Entropy loss\")\n",
    "axes[0].plot(range(n_train_epochs), train_xe_loss, label='Train loss')\n",
    "axes[0].set_title('Training Loss')\n",
    "axes[1].plot(range(n_train_epochs), val_xe_loss, label='Val loss')\n",
    "axes[1].set_title('Validation Loss')\n",
    "axes[2].plot(range(n_train_epochs), test_xe_loss, label='Test loss')\n",
    "axes[2].set_title('Testing Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model with best per-validation loss (uncomment when ready)\n",
    "best_epoch = load_state_dicts(out_file, model=model)\n",
    "print('per-validation optimal epoch', best_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconstruct from best model\n",
    "recons, losses, recon_losses, pred_labels = model.reconstruct(loaders['test'], device=device)\n",
    "recons = torch.cat(recons, dim=0)\n",
    "recon_losses = torch.stack(recon_losses)\n",
    "pred_labels = torch.cat(pred_labels, dim=0).cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, pred_labels = torch.max(pred_labels, 1)\n",
    "pred_labels = pred_labels.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recon_losses = recon_losses.cpu().numpy()\n",
    "mean_loss = np.mean(recon_losses)\n",
    "print('Reconstruction loss: ', mean_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Students TODO: MAKE your plots and analysis\n",
    "\n",
    "# 5 examples to visualize per questions (e, f)\n",
    "examples_to_visualize = ['8a67fd47001e52414c350d7ea5fe2a3a',\n",
    "                         '1e0580f443a9e6d2593ebeeedbff73b',\n",
    "                         'd3562f992aa405b214b1fd95dbca05',\n",
    "                         '4e8d8792a3a6390b36b0f2a1430e993a',\n",
    "                         '58479a7b7c157865e68f66efebc71317']\n",
    "# You can (also) use the function for the reconstructions or the part-predictions \n",
    "# (for the latter check the kwargs parameter 'c' of matplotlib.\n",
    "# plot_3d_point_cloud, eg. try plot_3d_point_cloud(loaders['test'].dataset.pointclouds[0])\n",
    "\n",
    "for example in examples_to_visualize:\n",
    "    print(\"Example: \", example)\n",
    "    index = np.where(loaders['test'].dataset.model_names == example)\n",
    "    index = np.int(index[0])\n",
    "    \n",
    "    orig = plot_3d_point_cloud(loaders['test'].dataset.pointclouds[index], title = 'original', c = loaders['test'].dataset.part_masks[index])\n",
    "    recon = plot_3d_point_cloud(recons[index].cpu(), title = 'reconstructed', c = pred_labels[index])\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#model.eval()   # Do not forget this.! We are not training any more (OK, since we do not \n",
    "               # have batch-norm, drop-out etc. this is not so important, however it is good standard \n",
    "               # practice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tolerance = 1e-10\n",
    "accuracy = (np.abs(pred_labels - loaders['test'].dataset.part_masks) < tolerance).mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best and worst\n",
    "min_example = accuracy.argmin()\n",
    "max_example = accuracy.argmax()\n",
    "\n",
    "\n",
    "print(\"Worst Example: \", example)\n",
    "print(\"Accuracy: \", accuracy.min())\n",
    "\n",
    "orig = plot_3d_point_cloud(loaders['test'].dataset.pointclouds[min_example], title = 'original',c = loaders['test'].dataset.part_masks[min_example])\n",
    "recon = plot_3d_point_cloud(recons[min_example].cpu(), title = 'reconstructed', c = pred_labels[min_example])\n",
    "\n",
    "print(\"Best Example: \", example)\n",
    "print(\"Accuracy: \", accuracy.max())\n",
    "\n",
    "orig = plot_3d_point_cloud(loaders['test'].dataset.pointclouds[max_example], title = 'original',c = loaders['test'].dataset.part_masks[max_example])\n",
    "recon = plot_3d_point_cloud(recons[max_example].cpu(), title = 'reconstructed', c = pred_labels[max_example])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
